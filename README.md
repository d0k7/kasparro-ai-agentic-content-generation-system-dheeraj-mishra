# Kasparro Applied AI Engineer Challenge: Multi-Agent Content Generation System

This repository implements a modular, agentic content generation pipeline that converts a single structured product dataset into multiple production-ready JSON content pages. The system leverages **LangChain** for LLM interactions and **LangGraph** for workflow orchestration.

### **Overview**

The system is designed to demonstrate real-world agentic system design, focusing on modularity, reusability, orchestration, and correctness. It integrates **LangChain** to utilize large language models (LLMs) for intelligent content generation and **LangGraph** for orchestrating workflows.

### **Outputs**

Running the pipeline generates the following artifacts:

- `outputs/faq.json` — FAQ page with categorized questions and answers
- `outputs/product_page.json` — Structured product description page
- `outputs/comparison_page.json` — Product comparison with a fictional Product B
- `outputs/dag_metadata.json` — DAG execution order, dependencies, and timing

### **Design Goals**

The design focuses on:

- **Single-responsibility agents**
- **Reusable logic blocks** shared across templates
- **Explicit DAG-based orchestration** using LangGraph
- **Structured JSON outputs** for consistent data handling
- **Deterministic execution** with snapshot tests to ensure output stability
- **Production-grade tooling** and testing

### **Frameworks and Tools Used**

- **LangChain**: Used for orchestrating LLMs (like OpenAI) for generating questions and answers.
- **LangGraph**: Used for orchestrating the overall workflow, ensuring each task (question generation, answer generation, etc.) is performed in sequence.
- **Puter**: A key component for leveraging real LLMs to generate questions and answers dynamically based on the provided product dataset.

### **Key Engineering Features**

1. **LangChain Integration**: Utilizes LangChain agents for intelligent reasoning and content generation.
2. **LangGraph Orchestration**: Uses LangGraph to define a Directed Acyclic Graph (DAG) that manages the flow of product data processing, question generation, and content creation.
3. **Puter LLM Integration**: Real LLMs (via Puter) are used for content generation, ensuring that the content is generated dynamically based on the product name. This adds an intelligent, real-time component to the system.

### **How to Run the Pipeline**

**Prerequisites**: 

- Python 3.8 or higher
- Virtual Environment setup

```bash
python -m venv kaspar
.\kaspar\Scripts\Activate.ps1  # For Windows
source kaspar/bin/activate  # For macOS/Linux

# Install dependencies
pip install --upgrade pip
pip install -r requirements-dev.txt


Run the Pipeline:

$env:PYTHONPATH="src"  # For Windows PowerShell
PYTHONPATH=src python -m kasparro_agentic --log-level INFO --out-dir outputs  # For Linux/MacOS


Project Structure:

src/kasparro_agentic/
├─ agents/                    # LLM agents for content generation
├─ core/                      # Core utilities (logging, validation, error handling)
├─ data/                      # RAW product data
├─ logic_blocks/              # Reusable content logic (FAQ, product, comparison)
├─ templates/                 # Template engine, page templates, registry
├─ orchestration/             # LangGraph-based orchestration (DAG)
├─ pipeline.py                # DAG construction and execution
└─ main.py                    # CLI entrypoint

tests/
├─ snapshots/                 # Deterministic expected JSON outputs
├─ test_pipeline.py           # Snapshot-based regression tests
└─ conftest.py                # PYTHONPATH setup

docs/
└─ projectdocumentation.md    # Detailed system design and architecture decisions


How It Works

LangGraph Workflow:

The system is orchestrated using LangGraph, a framework that helps in defining and executing workflows.

The graph nodes in LangGraph are defined to handle tasks such as:

Product Creation: Converts product name into structured data.

Question Generation: Uses Puter to generate questions related to the product dynamically.

Answer Generation: Uses Puter to generate answers for the product-related questions.

Puter Integration:

Puter is used to connect to real LLMs (like OpenAI). These LLMs generate questions and answers based on the given product name.

These agents are integrated into the workflow, ensuring intelligent content generation based on the product data.

Deterministic Guarantee (with real LLMs)

While this system is based on real LLMs for content generation, it still ensures:

No randomness: The output is generated by a real-time LLM but ensures consistent generation for the same input product name.

No external system dependencies: All content is generated using the provided product dataset, with real-time dynamic generation from Puter.

Snapshot Testing: Snapshot-based tests are used to check consistency and stability of output generation across runs.

Running Tests

To run the tests, use the following command:

How It Works

LangGraph Workflow:

The system is orchestrated using LangGraph, a framework that helps in defining and executing workflows.

The graph nodes in LangGraph are defined to handle tasks such as:

Product Creation: Converts product name into structured data.

Question Generation: Uses Puter to generate questions related to the product dynamically.

Answer Generation: Uses Puter to generate answers for the product-related questions.

Puter Integration:

Puter is used to connect to real LLMs (like OpenAI). These LLMs generate questions and answers based on the given product name.

These agents are integrated into the workflow, ensuring intelligent content generation based on the product data.

Deterministic Guarantee (with real LLMs)

While this system is based on real LLMs for content generation, it still ensures:

No randomness: The output is generated by a real-time LLM but ensures consistent generation for the same input product name.

No external system dependencies: All content is generated using the provided product dataset, with real-time dynamic generation from Puter.

Snapshot Testing: Snapshot-based tests are used to check consistency and stability of output generation across runs.

Running Tests

To run the tests, use the following command:

pytest -q


Frontend User Interface

Localhost Frontend: The system includes a local web interface where users can input a product name.

Dynamic Content Generation: When a product name is entered, the system generates questions and answers dynamically using Puter (real LLMs).

Users can interact with the system and see the generated content in real-time.



Important Notes :

Puter LLM Integration: The system uses Puter to interface with real LLMs (such as OpenAI) for dynamic content generation.

LangChain and LangGraph: These frameworks are used to ensure intelligent reasoning, orchestration, and workflow management.

Agentic System: The content generation is handled by real agents that interact with LLMs, providing real-time dynamic content generation based on the provided dataset.
